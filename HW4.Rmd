---
title: "HW4"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Packages
```{r load-packages}
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(stringr)
library(tidymodels) 
library(probably)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
```

# Data Cleaning
```{r data-cleaning}
executions <- read_csv("executiondata_clean.csv")

executions_clean <- executions %>%
  select(-Name) %>%
  separate(Date, c("Month", "Day", "Year"), sep = "/") %>%
  mutate(VictimMale = case_when(
    str_detect(Victim_Sex, "Male") ~ 1, TRUE ~ 0)) %>% # 1 if there was male victim(s)
  mutate(VictimFemale = case_when(
    str_detect(Victim_Sex, "Female") ~ 1, TRUE ~ 0)) %>% # 1 if there was female victim(s)
  mutate(VictimMixed = case_when(
    (VictimMale==1) & (VictimFemale==1) ~ 1, TRUE ~ 0)) %>% # 1 if the victim(s) were male and female
  mutate(VictimWhite = case_when(
    str_detect(Victim_Race, 'White') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimLatino = case_when(
    str_detect(Victim_Race, 'Latino') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimBlack = case_when(
    str_detect(Victim_Race, 'Black') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimAsian = case_when(
    str_detect(Victim_Race, 'Asian') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimMixedRace = case_when(
    str_detect(Victim_Race, ',') ~ 1, TRUE ~ 0)) %>%
  mutate(Electrocution = case_when(
    str_detect(Method, 'Electrocution') ~ 'yes', TRUE ~ 'no'))


executions_clean <- executions_clean %>% select(-Victim_Sex, -Day, -Victim_Race)
executions_clean$Month <-
  as.numeric(as.character(executions_clean$Month)) # turn month into numeric variable
executions_clean$Year <-
  as.numeric(as.character(executions_clean$Year)) # turn year into numeric variable
executions_clean$Electrocution <- factor(executions_clean$Electrocution, ordered = FALSE )
  
head(executions)
head(executions_clean)
```


# Research Question

We are looking to build a classification model that will predict the method of execution from our data set. To do this, we will use a logistic regression model and a random forests model. Our main aim is to determine if there is a specific method of execution that is more common in certain regions. 


# Logistic Regression

## Visualizations of Predictive Ability

Determined the variables with the most predictive ability are region, year, and race. The first graph shows that electrocution has only been used in the Midwest and South, with the South having a much higher use. The second graph shows that electrocution has mainly been used as a method of execution prior to 2000. Grpah 3 shows that electrocution has been used as a method of execution primarily for Black, Native American, and White individuals and for a small percentage of Latino individuals. Black individuals are the most common racial group to be executed with electrocution. The fourth and final graph shows the correlation between region and race. The Midwest and the South are the only two regions to have used electrocution as a method of execution, and have executed the vast majority of individuals in the data set. Most importantly, these two regions have executed the majority of Black individuals. 

```{r visualize-predictability}
ggplot(executions_clean, aes(x = Region, fill = Electrocution)) +
    geom_bar(position = 'fill')

ggplot(executions_clean, aes(x = Electrocution, y = Year)) + 
  geom_boxplot() + 
  theme_classic()

ggplot(executions_clean, aes(x = Race, fill = Electrocution)) + 
  geom_bar(position = 'fill')

ggplot(executions_clean, aes(x = Region, fill = Race)) + 
  geom_bar(position = 'dodge')
```


## Implementing Logistic Regression

```{r logistic-regression}
executions_clean <- executions_clean %>%
  mutate(Method = relevel(Electrocution, ref='no')) #set reference level

logistic_spec <- logistic_reg() %>%
    set_engine('glm') %>%
    set_mode('classification')

logistic_rec <- recipe(Electrocution ~ Year + Region + Race, data = executions_clean)

log_wf <- workflow() %>% 
    add_recipe(logistic_rec) %>%
    add_model(logistic_spec) 

log_fit <- fit(log_wf, data = executions_clean)
```

## Evaluating the Model

This graph of the ROC curve shows that the model is accurate, but not perfect. 

```{r evaluate-model}
logistic_output <-  executions_clean %>%
  bind_cols(predict(log_fit, new_data = executions_clean, type = 'prob')) 

logistic_roc <- logistic_output %>% 
    roc_curve(Electrocution, .pred_yes, event_level = "second") 

autoplot(logistic_roc) + theme_classic()
```

The model is overall 92% accurate. However, it is important to note that just under 11% of the executions in the data set used electrocution, creating a NIR of 89%. Furthermore, the model has a sensitivity of 57% which shows that there are nearly the same number of true positives as false negatives. The model is under-predicting electrocution as a method of execution. The model has a much higher specificity at 96.5%. This is due to the high number of true negatives in the data set.

```{r logistic-output}
logistic_output <-  executions_clean %>%
  bind_cols(predict(log_fit, new_data = executions_clean, type = 'prob')) 

logistic_output <- logistic_output %>%
  mutate(.pred_class = make_two_class_pred(`.pred_no`, levels(Electrocution), threshold = 0.63)) 

logistic_output %>%
  conf_mat(truth = Electrocution, estimate = .pred_class)

```

Looking at cross validated test metrics, the model's accuracy and specificity remain almost the same. Interestingly the sensitivity drops to 46%, meaning the cross validated data shows an even higher rate of predicting false negatives. It is also important to note that the AUC value is .898, which is greater than expected for such a low sensitivity rate. 

```{r logistic-cv}
set.seed(123)
data_cv10 <- vfold_cv(executions_clean, v = 10)

log_cv_fit <- fit_resamples(
    log_wf, 
    resamples = data_cv10,
    metrics = metric_set(sens, yardstick::spec, accuracy, roc_auc),
    control = control_resamples(save_pred = TRUE, event_level = 'second'))

collect_metrics(log_cv_fit)
```


# Random Forest

# Results

# Conclusion

