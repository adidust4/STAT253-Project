---
title: "Homework 3 Project"
author: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Packages
```{r load-packages}
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(stringr)
library(tidymodels) 
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
```

## Data Cleaning
```{r clean-data}
executions <- read_csv("executiondata_clean.csv")

executions_clean <- executions %>%
  filter(Victim_Count < 50) %>%
  select(-Name, -County) %>%
  separate(Date, c("Month", "Day", "Year"), sep = "/") %>%
  mutate(VictimMale = case_when(
    str_detect(Victim_Sex, "Male") ~ 1, TRUE ~ 0)) %>% # 1 if there was male victim(s)
  mutate(VictimFemale = case_when(
    str_detect(Victim_Sex, "Female") ~ 1, TRUE ~ 0)) %>% # 1 if there was female victim(s)
  mutate(VictimWhite = case_when(
    str_detect(Victim_Race, 'White') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimLatino = case_when(
    str_detect(Victim_Race, 'Latino') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimBlack = case_when(
    str_detect(Victim_Race, 'Black') ~ 1, TRUE ~ 0)) %>%
  mutate(VictimAsian = case_when(
    str_detect(Victim_Race, 'Asian') ~ 1, TRUE ~ 0)) 

executions_clean <- executions_clean %>% select(-Victim_Sex, -Day, -Victim_Race)
executions_clean$Month <-
  as.numeric(as.character(executions_clean$Month)) # turn month into numeric variable
executions_clean$Year <-
  as.numeric(as.character(executions_clean$Year)) # turn year into numeric variable
  
head(executions)
head(executions_clean) 
```

## Initial investigation: ignoring nonlinearity

### OLS Model
*Use ordinary least squares (OLS) by using the lm engine and LASSO (glmnet engine) to build a series of initial regression models for your quantitative outcome as a function of the predictors of interest. (As part of data cleaning, exclude any variables that you don’t want to consider as predictors.)*
```{r cv-setup}
set.seed(123)
execute_cv <- vfold_cv(executions_clean, v=10)
```

```{r linear-specifications}
# OLS spec
lm_spec <- linear_reg() %>%
  set_engine(engine = 'lm') %>%
    set_mode('regression')

# LASSO spec
lm_lasso_spec <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>%
  set_engine(engine = 'glmnet') %>%
  set_mode('regression')
```

### Recipes
*For each set of variables, you’ll need a recipe with the formula, data, and pre-processing steps*

```{r recipes-and-wf}
# create recipe
execute_rec <- recipe(Victim_Count~., data = executions_clean) %>%
  step_cut(Month, breaks=c(1, 3, 8, 12)) %>% # break months into winter, spring, summer, fall
  #step_cut(Year, breaks=c(1970, 1980, 1990, 2000, 2010, 2020)) %>% # break years into decades
  step_nzv(all_numeric_predictors()) %>% # remove near zero variance values
  step_corr(all_numeric_predictors()) %>% # remove correlated numeric variables
  step_normalize(all_numeric_predictors()) %>% # normalize numeric variables
  step_unknown(all_nominal_predictors()) %>% # mark NA for unknown nominal variables
  step_dummy(all_nominal_predictors()) # create indicator variables for all nominal variables

# create workflows
execute_wf <- workflow() %>%
  add_recipe(execute_rec) %>%
  add_model(lm_spec)

lasso_wf <- workflow() %>%
  add_recipe(execute_rec) %>%
  add_model(lm_lasso_spec)
```

```{r tune}
# tune LASSO penalty term
penalty_grid <- grid_regular(
  penalty(range = c(-4, 0)), # range picked based on autoplot trial and error
  levels = 50
)

tune_res <- tune_grid(
  lasso_wf, 
  resamples = execute_cv,
  metrics = metric_set(rmse),
  grid = penalty_grid
)

autoplot(tune_res) # to find a good range of values to tune from, can be commented out

collect_metrics(tune_res) %>%
  filter(.metric == 'rmse') %>% # using root mean squared error
  select(penalty, rmse = mean)

best_penalty <- select_best(tune_res, metric = 'rmse')

lasso_tuned_wf <- finalize_workflow(lasso_wf, best_penalty)
```

```{r fit-models}
# fit models
fit_model <- fit(execute_wf, data = executions_clean)
tidy(fit_model)

fit_model_lasso <- fit(lasso_tuned_wf, data = executions_clean)
tidy(fit_model_lasso)
```


### Test Performance
*Estimate the test performance of the models using CV. Report and interpret (with units) the CV metric estimates along with a measure of uncertainty in the estimate*
```{r fit-cv}
# fit models using cross validation
fit_resamples(execute_wf, 
      resamples = execute_cv, 
      metrics = metric_set(rmse, rsq, mae))  %>%
      collect_metrics(summarize = TRUE)

fit_resamples(lasso_tuned_wf, 
      resamples = execute_cv, 
      metrics = metric_set(rmse, rsq, mae))  %>%
      collect_metrics(summarize = TRUE)
```

### Residual Plots
*Use residual plots to evaluate whether some quantitative predictors might be better modeled with nonlinear relationships.*

```{r residuals}
# OLS MODEL
# create data frame with predicted values and residuals
mod_output <- fit_model %>%
    predict(new_data = executions_clean) %>%
    bind_cols(executions_clean) %>%
    mutate(resid = Victim_Count - .pred)

# residual versus predicted scatter plot
mod_output %>%
  ggplot(aes(x = .pred, y = resid)) +
    geom_point() + 
    geom_smooth()+
    theme_classic()

# residual versus age scatter plot
mod_output %>%
  ggplot(aes(x = Age, y = resid)) +
    geom_point() + 
    geom_smooth() +
    theme_classic()

# residual versus year scatter plot
mod_output %>%
  ggplot(aes(x = Year, y = resid)) +
    geom_point() + 
    geom_smooth() +
    theme_classic()

## LASSO MODEL 
# create data frame with predicted values and residuals
mod_output_2 <- fit_model_lasso %>%
    predict(new_data = executions_clean) %>%
    bind_cols(executions_clean) %>%
    mutate(resid = Victim_Count - .pred)

# residual versus predicted scatter plot
mod_output_2 %>%
  ggplot(aes(x = .pred, y = resid)) +
    geom_point() + 
    geom_smooth() +
    theme_classic()

# residual versus age scatter plot
mod_output_2 %>%
  ggplot(aes(x = Age, y = resid)) +
    geom_point() + 
    geom_smooth() +
    theme_classic()

# residual versus year scatter plot
mod_output_2 %>%
  ggplot(aes(x = Year, y = resid)) +
    geom_point() + 
    geom_smooth() +
    theme_classic()
```

### Variable Importance
*Which variables do you think are the most important predictors of your quantitative outcome? Justify your answer. Do the methods you’ve applied reach consensus on which variables are most important? What insights are expected? Surprising?*

```{r variable-importance}

glmnet_output <- fit_model_lasso %>% extract_fit_engine()
    
# Create a boolean matrix (predictors x lambdas) of variable exclusion
bool_predictor_exclude <- glmnet_output$beta==0

# Loop over each variable
var_imp <- sapply(seq_len(nrow(bool_predictor_exclude)), function(row) {
    this_coeff_path <- bool_predictor_exclude[row,]
    if(sum(this_coeff_path) == ncol(bool_predictor_exclude)){ return(0)}else{
    return(ncol(bool_predictor_exclude) - which.min(this_coeff_path) + 1)}
})

# Create a dataset of this information and sort
var_imp_data <- tibble(
    var_name = rownames(bool_predictor_exclude),
    var_imp = var_imp
)
var_imp_data %>% arrange(desc(var_imp)) # most important variable first
```


## Accounting for nonlinearity

## Summarize investigations

## Societal impact